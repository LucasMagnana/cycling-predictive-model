{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "import torch\n",
    "\n",
    "import python.voxels as voxels\n",
    "import python.RNN as RNN\n",
    "import python.clustering as cl\n",
    "\n",
    "project_folder = \"veleval\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './files/veleval/neural_networks/saved/num_test.tab'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-230576d27c9a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"./files/\"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mproject_folder\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\"/neural_networks/saved/network.param\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0minfile\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mparam\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"./files/\"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mproject_folder\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\"/neural_networks/saved/num_test.tab\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0minfile\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m     \u001b[0mtab_num_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './files/veleval/neural_networks/saved/num_test.tab'"
     ]
    }
   ],
   "source": [
    "with open(\"./files/\"+project_folder+\"/data_processed/osmnx_pathfinding_simplified.df\",'rb') as infile:\n",
    "    df_pathfinding = pickle.load(infile)\n",
    "with open(\"./files/\"+project_folder+\"/clustering/dbscan_observations.tab\",'rb') as infile:\n",
    "    tab_clusters = pickle.load(infile)\n",
    "with open(\"./files/\"+project_folder+\"/clustering/voxels_clustered_osmnx.dict\",'rb') as infile:\n",
    "    dict_voxels = pickle.load(infile)\n",
    "with open(\"./files/\"+project_folder+\"/neural_networks/saved/network.param\",'rb') as infile:\n",
    "    param = pickle.load(infile)\n",
    "with open(\"./files/\"+project_folder+\"/neural_networks/saved/num_test.tab\",'rb') as infile:\n",
    "    tab_num_test = pickle.load(infile)\n",
    "    \n",
    "\n",
    "size_data = 1\n",
    "\n",
    "df = df_pathfinding\n",
    "\n",
    "tab_routes_voxels, _, _ = voxels.generate_voxels(df, df.iloc[0][\"route_num\"], df.iloc[-1][\"route_num\"])\n",
    "tab_routes_voxels_int = []\n",
    "\n",
    "df_voxels = pd.DataFrame()\n",
    "df_voxels_train = pd.DataFrame()\n",
    "\n",
    "dict_clusters = cl.tab_clusters_to_dict(tab_clusters)\n",
    "\n",
    "network = RNN.RNN_LSTM(size_data, max(tab_clusters)+1, param.hidden_size, param.num_layers, param.bidirectional, param.dropout)\n",
    "network.load_state_dict(torch.load(\"files/\"+project_folder+\"/neural_networks/saved/network_temp.pt\"))\n",
    "network.eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(tab_num_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tab_results = []\n",
    "tab_routes_voxels_int = []\n",
    "for i in range(len(tab_routes_voxels)):\n",
    "    nb_vox = 0\n",
    "    tab_routes_voxels_int.append([])\n",
    "    route = tab_routes_voxels[i]\n",
    "    for vox in route:\n",
    "        if(nb_vox%param.voxels_frequency==0): #(len(tab_routes_voxels_int[i])==0 or tab_routes_voxels_int[i][-1][0] != dict_voxels[vox][\"cluster\"]): \n",
    "            points = [dict_voxels[vox][\"cluster\"]+1]\n",
    "            tab_routes_voxels_int[i].append(points)\n",
    "        nb_vox += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tab_routes_voxels_int[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_prediction_test = 0\n",
    "nb_good_prediction_test = 0\n",
    "nb_prediction_train = 0\n",
    "nb_good_prediction_train = 0\n",
    "tab_fail_test = []\n",
    "tab_fail_train = []\n",
    "\n",
    "for i in range(len(tab_routes_voxels_int)):\n",
    "\n",
    "    tens_route = torch.Tensor(tab_routes_voxels_int[i]).unsqueeze(1)\n",
    "\n",
    "    hidden = network.initHidden()\n",
    "    for j in range(tens_route.shape[0]):\n",
    "        input = tens_route[j].unsqueeze(1)\n",
    "        output, hidden = network(input, hidden)\n",
    "    pred = output.argmax(dim=1, keepdim=True)\n",
    "    \n",
    "    tab_results.append({\"probabilities\": output, \"good_result\": pred==tab_clusters[i]})\n",
    "    \n",
    "    if(i in tab_num_test):\n",
    "        tab_results[-1][\"test\"] = True\n",
    "        nb_prediction_test+=1\n",
    "        if(pred==tab_clusters[i]):\n",
    "            nb_good_prediction_test+=1\n",
    "    else:\n",
    "        tab_results[-1][\"test\"] = False\n",
    "        nb_prediction_train+=1\n",
    "        if(pred==tab_clusters[i]):\n",
    "            nb_good_prediction_train+=1\n",
    "    \n",
    "            \n",
    "print(\"Good train predict:\", nb_good_prediction_train/nb_prediction_train*100, \"%\")\n",
    "print(\"Good test predict:\", nb_good_prediction_test/nb_prediction_test*100, \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(tab_routes_voxels_int), len(tab_routes_voxels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
